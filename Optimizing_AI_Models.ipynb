{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model Optimization Techniques\n",
    "\n",
    "    AI model optimization techniques refer to methods used to improve model performance, efficiency, and robustness during training and inference. These techniques are essential for dealing with issues such as overfitting, underfitting, slow convergence, and inefficient use of computational resources. \n",
    "\n",
    "\n",
    "## What is overfitting, underfitting, slow convergence in Artificial Intelligence\n",
    "\n",
    "    In Artificial Intelligence (AI) and Machine Learning (ML), the performance of a model is influenced by how well it generalizes to new, unseen data. Key concepts related to model performance include overfitting, underfitting, and slow convergence:\n",
    "\n",
    "## 1. Overfitting\n",
    "\n",
    "    Overfitting occurs when a model learns the details and noise in the training data to such an extent that it negatively impacts its performance on new data (test data or real-world data). \n",
    "    \n",
    "    The model becomes too complex and overly sensitive to the training data, capturing both the signal (relevant patterns) and the noise (irrelevant details).\n",
    "\n",
    "    Symptoms:\n",
    "    High accuracy on training data but poor performance on test data.\n",
    "\n",
    "    The model has memorized the training set rather than learning general patterns.\n",
    "\n",
    "    Example: If a neural network is trained on a small dataset with many parameters, it might learn irrelevant details specific to that dataset, leading to poor generalization.\n",
    "\n",
    "    Solution:\n",
    "    Regularization techniques (e.g., L1/L2 regularization, dropout in neural networks).\n",
    "\n",
    "    Cross-validation to monitor performance on validation data.\n",
    "\n",
    "    Simplifying the model by reducing the number of parameters.\n",
    "    \n",
    "    More data to help the model learn more generalizable patterns.\n",
    " \n",
    "## 2. Underfitting\n",
    "\n",
    "    Underfitting occurs when a model is too simple to capture the underlying patterns in the data. \n",
    "    \n",
    "    This can happen when the model has too few parameters or when it's not given enough training time. \n",
    "    As a result, the model performs poorly both on the training data and the test data.\n",
    "\n",
    "\n",
    "    Symptoms:\n",
    "    Low accuracy on both the training data and the test data.\n",
    "    The model is unable to capture the important patterns in the data.\n",
    "    \n",
    "    Example: A linear model being used to fit data with a nonlinear relationship will result in underfitting because the model is too simplistic to represent the data's complexity.\n",
    "\n",
    "    Solution:\n",
    "    Increase the model complexity (e.g., using deeper neural networks or more features).\n",
    "\n",
    "    Train the model longer to allow it to capture patterns in the data.\n",
    "    \n",
    "    Feature engineering to add more informative features.\n",
    " \n",
    "\n",
    "## 3. Slow Convergence\n",
    "\n",
    "    Slow convergence refers to the phenomenon where the training of a machine learning model progresses very slowly.\n",
    "    \n",
    "    It takes a long time for the model to reach an optimal solution or a satisfactory level of accuracy. \n",
    "    \n",
    "    Convergence is typically related to how quickly the optimization algorithm (e.g., gradient descent) minimizes the loss function.\n",
    "\n",
    "\n",
    "    Symptoms:\n",
    "    The model’s performance improves very slowly during training.\n",
    "\n",
    "    It takes many epochs (iterations) for the model to reach an acceptable level of accuracy or loss reduction.\n",
    "\n",
    "    Example: When using a neural network, if the learning rate is too low or the initialization of parameters is poor, the model may take a long time to converge to a minimum.\n",
    "\n",
    "    Solution:\n",
    "    Increase the learning rate (but not too high, or it can cause divergence).\n",
    "\n",
    "    Use adaptive optimization algorithms (e.g., Adam, RMSprop) that adjust learning rates dynamically.\n",
    "\n",
    "    Normalize the data to ensure all features are on a similar scale, which helps the model converge faster.\n",
    "\n",
    "    Use batch normalization or momentum in gradient descent to speed up convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques for Quantization, Pruning, and Compression\n",
    "\n",
    "    Quantization, pruning, and compression techniques are essential strategies for optimizing AI models, particularly when deploying them in resource-constrained environments (such as mobile devices, edge computing, or IoT). \n",
    "\n",
    "    These techniques reduce the model’s size, computational requirements, and energy consumption, while maintaining (or minimally affecting) accuracy.\n",
    "\n",
    "## 1. Quantization\n",
    "    Quantization reduces the precision of the numbers representing model parameters (such as weights and activations) from 32-bit floating-point numbers to lower-bit representations (like 16-bit, 8-bit, or even lower). This leads to smaller model sizes and faster inference times.\n",
    "\n",
    "    Techniques:\n",
    "    Post-Training Quantization:\n",
    "\n",
    "    Convert the model after it has been fully trained. It’s the most common approach because it doesn’t require changes to the training process.\n",
    "\n",
    "    Types include:\n",
    "\n",
    "    Dynamic Range Quantization: Only weights are quantized, typically from 32-bit floating-point to 8-bit integers.\n",
    "\n",
    "    Full Integer Quantization: Both weights and activations are quantized to 8-bit integers.\n",
    "    \n",
    "    Float16 Quantization: Weights are stored in float16 format (half precision), which reduces the size without impacting performance as significantly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization, pruning, and compression\n",
    "\n",
    "Quantization, pruning, and compression are popular techniques to optimize machine learning models for deployment in resource-constrained environments (like mobile or embedded devices). These techniques help reduce the model's size and improve inference speed while maintaining acceptable performance.\n",
    "\n",
    "Here’s a step-by-step guide to applying these techniques using TensorFlow with Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Install TensorFlow and Other Necessary Libraries\n",
    "\n",
    "    Make sure you have TensorFlow installed. If not, install it using:\n",
    "\n",
    "    pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define and Train a Simple Model\n",
    "\n",
    "For this example, we’ll use the MNIST dataset and build a basic neural network to classify handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.3153 - val_accuracy: 0.9828 - val_loss: 0.0605\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9824 - loss: 0.0552 - val_accuracy: 0.9832 - val_loss: 0.0611\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0323 - val_accuracy: 0.9865 - val_loss: 0.0552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae955d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
    "\n",
    "\n",
    "# Reshape data to add a channel dimension\n",
    "x_train = x_train[..., np.newaxis]\n",
    "\n",
    "x_test = x_test[..., np.newaxis]\n",
    "\n",
    "# Build a simple model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Quantization\n",
    "\n",
    "    Quantization reduces the precision of the model’s weights and activations, commonly from 32-bit floating point (float32) to 8-bit integer (int8), which results in a smaller model size and faster inference.\n",
    "\n",
    "\n",
    "## 3.1 Post-Training Quantization\n",
    "\n",
    "    TensorFlow provides several quantization options. Here, we’ll use post-training quantization to convert the model to 8-bit precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/surendra/ai_embed/Machinelearnex/savemodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/surendra/ai_embed/Machinelearnex/savemodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/Users/surendra/ai_embed/Machinelearnex/savemodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  6262029584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6262025552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6262025744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6264948304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6264947344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6264947920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "#help(model)\n",
    "#print(model.variables)\n",
    "model.export(\"/Users/surendra/ai_embed/Machinelearnex/savemodel\",format='tf_saved_model',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730190346.956310 1148170 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1730190346.956600 1148170 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-10-29 13:55:46.957039: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /Users/surendra/ai_embed/Machinelearnex/savemodel\n",
      "2024-10-29 13:55:46.957414: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-29 13:55:46.957419: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /Users/surendra/ai_embed/Machinelearnex/savemodel\n",
      "2024-10-29 13:55:46.960835: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-29 13:55:46.984755: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /Users/surendra/ai_embed/Machinelearnex/savemodel\n",
      "2024-10-29 13:55:46.990548: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 33512 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Example: TensorFlow Lite post-training quantization\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/Users/surendra/ai_embed/Machinelearnex/savemodel')\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpq0komsft/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpq0komsft/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpq0komsft'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  6262029584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6262025552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6262025744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6264948304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6264947344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6264947920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730190407.835683 1148170 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1730190407.835695 1148170 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-10-29 13:56:47.835813: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpq0komsft\n",
      "2024-10-29 13:56:47.836157: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-29 13:56:47.836162: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpq0komsft\n",
      "2024-10-29 13:56:47.839198: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-29 13:56:47.858164: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpq0komsft\n",
      "2024-10-29 13:56:47.864361: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 28548 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TensorFlow Lite format with quantization\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Apply default quantization\n",
    "\n",
    "tflite_model_quantized = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open(\"model_quantized.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model_quantized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pruning\n",
    "\n",
    "    Pruning involves removing unnecessary neurons or parameters from a model, reducing its size and computation complexity without significantly impacting its performance. \n",
    "\n",
    "    The idea is that not all parameters contribute equally to the model’s predictions, so redundant or less impactful ones can be removed.\n",
    "\n",
    "    Techniques:\n",
    "\n",
    "    Magnitude-based Pruning:\n",
    "    \n",
    "    Remove weights that are smaller than a predefined threshold. This is the simplest and most common type of pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /opt/anaconda3/lib/python3.11/site-packages (from tf_keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf_keras) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf_keras\n",
      "Successfully installed tf_keras-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_model_optimization in /opt/anaconda3/lib/python3.11/site-packages (0.8.0)\n",
      "Requirement already satisfied: absl-py~=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_model_optimization) (1.4.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_model_optimization) (0.1.8)\n",
      "Requirement already satisfied: numpy~=1.23 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_model_optimization) (1.26.4)\n",
      "Requirement already satisfied: six~=1.14 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_model_optimization) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install tensorflow_model_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning in Keras example\n",
    "\n",
    "    Train a keras model for MNIST from scratch.\n",
    "\n",
    "    Fine tune the model by applying the pruning API and see the accuracy.\n",
    "\n",
    "    Create 3x smaller TF and TFLite models from pruning.\n",
    "\n",
    "    Create a 10x smaller TFLite model from combining pruning and post-training quantization.\n",
    "    \n",
    "    See the persistence of accuracy from TF to TFLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model for MNIST without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3283 - accuracy: 0.9074 - val_loss: 0.1433 - val_accuracy: 0.9588\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1386 - accuracy: 0.9603 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9737 - val_loss: 0.0748 - val_accuracy: 0.9792\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0711 - accuracy: 0.9794 - val_loss: 0.0744 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x14a63d650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate baseline test accuracy and save the model for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9781000018119812\n",
      "Saved baseline model to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpse81zmjp.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/ipykernel_77769/3790298460.py:7: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model, keras_file, include_optimizer=False)\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune pre-trained model with pruning\n",
    "\n",
    "    Define the model\n",
    "\n",
    "    You will apply pruning to the whole model and see this in the model summary.\n",
    "\n",
    "    In this example, you start the model with 50% sparsity (50% zeros in weights) and end with 80% sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
      " e (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
      " oling2d (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 2028)              1         \n",
      " n (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 10)                40572     \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40805 (159.41 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 20395 (79.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate the model against baseline\n",
    "\n",
    "## Fine tune with pruning for two epochs.\n",
    "\n",
    "    tfmot.sparsity.keras.UpdatePruningStep is required during training, and \n",
    "    tfmot.sparsity.keras.PruningSummaries provides logs for tracking progress and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.1105 - accuracy: 0.9694 - val_loss: 0.1219 - val_accuracy: 0.9683\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.1151 - accuracy: 0.9705 - val_loss: 0.0928 - val_accuracy: 0.9763\n",
      "Baseline test accuracy: 0.9781000018119812\n",
      "Pruned test accuracy: 0.9685999751091003\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "# For this example, there is minimal loss in test accuracy after pruning, compared to the baseline.\n",
    "\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The logs show the progression of sparsity on a per-layer basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 3x smaller models from pruning\n",
    "\n",
    "    Both tfmot.sparsity.keras.strip_pruning and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression benefits of pruning.\n",
    "\n",
    "    strip_pruning is necessary since it removes every tf.Variable that pruning only needs during training, which would otherwise add to model size during inference\n",
    "\n",
    "    Applying a standard compression algorithm is necessary since the serialized weight matrices are the same size as they were before pruning. However, pruning makes most of the weights zeros, which is added redundancy that algorithms can utilize to further compress the model.\n",
    "\n",
    "    First, create a compressible model for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved pruned Keras model to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpjojz6g0h.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/ipykernel_77769/3267383138.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a compressible model for TFLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmp0fdzp_t5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmp0fdzp_t5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpgpi4fy_k.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1730209385.128790 1372965 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1730209385.129009 1372965 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-10-29 19:13:05.129529: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmp0fdzp_t5\n",
      "2024-10-29 19:13:05.130033: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-29 19:13:05.130038: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmp0fdzp_t5\n",
      "I0000 00:00:1730209385.132777 1372965 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-10-29 19:13:05.133151: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-29 19:13:05.146976: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmp0fdzp_t5\n",
      "2024-10-29 19:13:05.151006: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 21483 microseconds.\n",
      "2024-10-29 19:13:05.176764: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a helper function to actually compress the models via gzip and measure the zipped size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare and see that the models are 3x smaller from pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78292.00 bytes\n",
      "Size of gzipped pruned Keras model: 25819.00 bytes\n",
      "Size of gzipped pruned TFlite model: 24967.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a 10x smaller model from combining pruning and quantization\n",
    "\n",
    "    You can apply post-training quantization to the pruned model for additional benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpvjywptjd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpvjywptjd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpx3vplcmm.tflite\n",
      "Size of gzipped baseline Keras model: 78292.00 bytes\n",
      "Size of gzipped pruned and quantized TFlite model: 8685.00 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730209447.916397 1372965 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1730209447.916422 1372965 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-10-29 19:14:07.916544: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpvjywptjd\n",
      "2024-10-29 19:14:07.916992: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-29 19:14:07.916997: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpvjywptjd\n",
      "2024-10-29 19:14:07.919693: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-29 19:14:07.929450: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/j9/t7f_l7rd20101rcpcynrvqyh0000gn/T/tmpvjywptjd\n",
      "2024-10-29 19:14:07.933530: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 16986 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See persistence of accuracy from TF to TFLite\n",
    "\n",
    "    Define a helper function to evaluate the TF Lite model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You evaluate the pruned and quantized model and see that the accuracy from TensorFlow persists to the TFLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Pruned and quantized TFLite test_accuracy: 0.9688\n",
      "Pruned TF test accuracy: 0.9685999751091003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "    We saw how to create sparse models with the TensorFlow Model Optimization Toolkit API for both TensorFlow and TFLite. You then combined pruning with post-training quantization for additional benefits.\n",
    "\n",
    "    We created a 10x smaller model for MNIST, with minimal accuracy difference.\n",
    "\n",
    "    We encourage you to try this new capability, which can be particularly important for deployment in resource-constrained environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2888 - accuracy: 0.9170 - val_loss: 0.1142 - val_accuracy: 0.9700\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1144 - accuracy: 0.9671 - val_loss: 0.0856 - val_accuracy: 0.9785\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9748 - val_loss: 0.0731 - val_accuracy: 0.9812\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0733 - accuracy: 0.9790 - val_loss: 0.0648 - val_accuracy: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x12e997c90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
      " e_1 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
      " oling2d_1 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 2028)              1         \n",
      " n_1 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                40572     \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40805 (159.41 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 20395 (79.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

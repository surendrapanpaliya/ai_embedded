{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to OpenAI's APIs\n",
    "\n",
    "OpenAI offers several powerful APIs designed for a wide range of AI-driven tasks, such as natural language processing, image generation, code generation, and speech-to-text conversions. These APIs enable developers to integrate advanced AI functionalities into their applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT (Generative Pretrained Transformer) API\n",
    "\n",
    "Overview:\n",
    "\n",
    "The GPT API allows developers to interact with the GPT models, including the famous GPT-4, for various text-based tasks. GPT is a highly versatile language model that can generate human-like text, answer questions, summarize information, translate languages, and even write creative content.\n",
    "\n",
    "Key Use Cases:\n",
    "\n",
    "Text generation: Automatically generate coherent, human-like text based on a prompt.\n",
    "\n",
    "Content creation: Blogs, articles, or creative writing generation.\n",
    "\n",
    "Chatbots: Build conversational agents capable of understanding and responding to natural language inputs.\n",
    "\n",
    "Summarization: Summarize lengthy documents or articles.\n",
    "\n",
    "Translation: Translate text between different languages.\n",
    "\n",
    "Text classification and analysis: Sentiment analysis, topic extraction, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example GPT API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.51.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#help(OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Key Initialization:\n",
    "\n",
    "    api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    You initialize the OpenAI client with your API key to authenticate API requests. \n",
    "\n",
    "    Note: Never expose your API key in publicly accessible code (e.g., in this case, the API key in the example is sensitive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Chat Completion:\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is OpenAI?\"}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        n=3,  # Return 3 different responses\n",
    "        presence_penalty=0.6,\n",
    "        frequency_penalty=0.5\n",
    "    )\n",
    "\n",
    "    model=\"gpt-4\": Specifies that you are using the GPT-4 model.\n",
    "\n",
    "    messages: Defines the conversation. The system message sets the context for the assistant, while the user provides the actual questions.\n",
    "\n",
    "    max_tokens=150: Limits the length of each response to approximately 150 tokens (about 100–120 words).\n",
    "\n",
    "    temperature=0.7: Controls the creativity of the model. Lower values (close to 0) produce more \n",
    "    deterministic and focused responses, while higher values (closer to 2) produce more creative responses.\n",
    "\n",
    "    top_p=0.9: Another parameter that controls randomness, but it works differently from temperature. It sets the probability of considering a broader set of potential responses.\n",
    "\n",
    "    n=3: Specifies that the API should return 3 different responses to the same prompt.\n",
    "\n",
    "    presence_penalty: Encourages the model to talk about new topics, reducing repetition.\n",
    "\n",
    "    frequency_penalty: Reduces the chances of the model repeating the same phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Through the Responses:\n",
    "\n",
    "    for i, choice in enumerate(response.choices[:]):\n",
    "        print(f\"Response {i+1}:\\n{choice.message.content.strip()}\\n\")\n",
    "        print(\"-\" * 50)  # Separator between responses\n",
    "\n",
    "\n",
    "    Loops through the 3 responses and prints each one. \n",
    "    It adds a separator (\"-\" * 50) between them for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x1100c4810>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chatgptex.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "user_prompt = input(\"Ask Question?\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt },\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=2,\n",
    "    top_p=0.9,\n",
    "    n=3,  # Return 3 different responses\n",
    "    presence_penalty=0.6,\n",
    "    frequency_penalty=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Print all responses\n",
    "for i, choice in enumerate(response.choices[:]):\n",
    "    print(f\"Response {i+1}:\\n{choice.message.content.strip()}\\n\")\n",
    "    print(\"-\" * 50)  # Separator between responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requesting Coding Help\n",
    "\n",
    "    Let’s say you want the assistant to help with coding in Python.\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a Python programming assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I reverse a list in Python?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the time complexity of this operation?\"}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.5,  # More deterministic and factual\n",
    "    n=1  # Return only 1 response\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.chat.completions.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "The time complexity of reversing a list in Python using the `reverse()` function or slicing `[::-1]` is O(n), where n is the length of the list. This is because every element in the list must be repositioned.\n",
      "\n",
      "Response 2:\n",
      "Reversing a list in Python using the `reverse()` function or slicing technique is an O(n) operation, where n is the number of elements in the list. This is because each element in the list must be repositioned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a Python programming assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I reverse a list in Python?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the time complexity of this operation?\"}\n",
    "    ],\n",
    "    max_tokens=200,\n",
    "    temperature=0.5,  # More deterministic and factual\n",
    "    n=2  # Return 2 responses\n",
    ")\n",
    "\n",
    "#print(response.choices[0].message.content.strip())\n",
    "\n",
    "# Print all responses\n",
    "for i, choice in enumerate(response.choices[:]):\n",
    "    print(f\"Response {i+1}:\\n{choice.message.content.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example : Asking for General Knowledge\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in general information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Who is Albert Einstein?\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is his most famous theory?\"}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        n=1\n",
    "    )\n",
    "    print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative Story Prompt\n",
    "\n",
    "    You can generate multiple creative stories using the same prompt.\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a creative writing assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me a short story about a dragon and a knight.\"}\n",
    "        ],\n",
    "        max_tokens=200,\n",
    "        temperature=1.0,  # Make it more creative\n",
    "        n=3  # Generate 3 different stories\n",
    "    )\n",
    "\n",
    "    for i, choice in enumerate(response.choices[:]):\n",
    "        print(f\"Story {i+1}:\\n{choice.message.content.strip()}\\n\")\n",
    "        print(\"-\" * 50)  # Separator between stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give you 3 different short stories based on the same prompt, allowing you to see the diversity in the model's creativity.\n",
    "\n",
    "# Best Practices:\n",
    "\n",
    "    System Messages: Use system messages effectively to set up the context for the assistant (e.g., a Python expert, creative writer, etc.).\n",
    "\n",
    "    Parameter Tuning: Experiment with parameters like temperature, max_tokens, n, and penalties (presence_penalty, frequency_penalty) to get the kind of response you need.\n",
    "\n",
    "    Token Limits: Be mindful of token limits, especially if you need longer responses. Adjust max_tokens accordingly.\n",
    "\n",
    "    Multiple Responses: Use n if you want multiple responses to explore different outputs for the same query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DALL·E API (Image Generation from Text)\n",
    "\n",
    "    The DALL·E API generates images based on textual descriptions. \n",
    "    DALL-E-2, DALL-E-3 are advanced version of this model, \n",
    "    can create highly detailed and imaginative images, \n",
    "    blending various styles and objects based on the input prompt.\n",
    "\n",
    "# Key Use Cases:\n",
    "\n",
    "    Image generation from text: Convert text descriptions into unique, high-quality images.\n",
    "\n",
    "    Creative designs: Generate illustrations, logos, and artwork from textual input.\n",
    "\n",
    "    Concept visualization: Visualize ideas or concepts for marketing, storytelling, or product design.\n",
    "\n",
    "    Game assets: Generate custom assets for video games and virtual worlds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries:\n",
    "\n",
    "    os: Allows access to environment variables, which is where the API key is stored.\n",
    "    OpenAI: A class from the OpenAI SDK that handles API requests.\n",
    "\n",
    "# Set Up the OpenAI API Key:\n",
    "\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "    The api_key is obtained from an environment variable called OPENAI_API_KEY. \n",
    "    This is more secure than hardcoding the API key directly in the code.\n",
    "\n",
    "# Initialize  the OpenAI API Client:\n",
    "\n",
    "    openai = OpenAI(api_key=api_key)\n",
    "\n",
    "    This line creates an instance of the OpenAI client, using the provided API key to authenticate with the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "# Set up the OpenAI API key\n",
    "\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Prompt and Model:\n",
    "\n",
    "    prompt = \"An astronaut lounging in a tropical resort in space, pixel art\"\n",
    "    model = \"dall-e-3\"\n",
    "\n",
    "    The prompt variable defines the description of the image you want DALL-E to generate.\n",
    "    The model variable specifies the model to use, which is DALL-E 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"An astronaut lounging in a tropical resort in space, pixel art\"\n",
    "model = \"dall-e-3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function:\n",
    "\n",
    "    def main() -> None:\n",
    "\n",
    "    This function calls the OpenAI API to generate an image based on the prompt and model specified.\n",
    "\n",
    "# Generate Image:\n",
    "\n",
    "    response = openai.images.generate(prompt=prompt, model=model)\n",
    "\n",
    "    This line calls the generate method of the openai.images object, sending the prompt and model as parameters. It returns a response object that contains the image URL.\n",
    "\n",
    "# Print the Response:\n",
    "\n",
    "    print(response)\n",
    "    The response, which includes the URL to the generated image, is printed.\n",
    "\n",
    "# Run the Main Function:\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()\n",
    "\n",
    "    This ensures that main is only called if the script is run directly, not if it’s imported as a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    # Generate an image based on the prompt\n",
    "    response = openai.images.generate(prompt=prompt, model=model)\n",
    "\n",
    "    # Prints response containing a URL link to image\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Openai_dalle.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Openai_dalle.py\n",
    "import os\n",
    "from openai import OpenAI\n",
    "# Set up the OpenAI API key\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt = \"An astronaut lounging in a tropical resort in space, pixel art\"\n",
    "model = \"dall-e-3\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # Generate an image based on the prompt\n",
    "    response = openai.images.generate(prompt=prompt, model=model)\n",
    "\n",
    "    # Prints response containing a URL link to image\n",
    "    print(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Above Programme from Command Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate an Inspirational Quote Image with Text-to-Image:\n",
    "\n",
    "    prompt = \"A beautiful sunset over a mountain with an inspirational quote, digital art\"\n",
    "    model = \"dall-e-3\"\n",
    "\n",
    "    def main() -> None:\n",
    "        response = openai.images.generate(prompt=prompt, model=model)\n",
    "        print(response)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Cartoon Character Based on a Description:\n",
    "\n",
    "    prompt = \"A friendly cartoon character with a smile, wearing glasses and a backpack, animation style\"\n",
    "    model = \"dall-e-3\"\n",
    "\n",
    "    def main() -> None:\n",
    "        response = openai.images.generate(prompt=prompt, model=model)\n",
    "        print(response)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Sci-Fi Landscape for a Video Game Concept:\n",
    "\n",
    "\n",
    "    prompt = \"A futuristic cityscape with flying cars and neon lights, sci-fi style\"\n",
    "    model = \"dall-e-3\"\n",
    "\n",
    "    def main() -> None:\n",
    "        response = openai.images.generate(prompt=prompt, model=model)\n",
    "        print(response)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Fantasy Forest Scene:\n",
    "\n",
    "\n",
    "    prompt = \"An enchanted forest with glowing mushrooms and magical creatures, fantasy style\"\n",
    "    model = \"dall-e-3\"\n",
    "\n",
    "    def main() -> None:\n",
    "        response = openai.images.generate(prompt=prompt, model=model)\n",
    "        print(response)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the OpenAI API to interact with GPT-4 in a conversational manner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-AFXPO9ij1F5ko4XPjrHk0qVOAM66t', 'object': 'chat.completion', 'created': 1728266706, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Sure, I\\'d be happy to explain how to use OpenAI\\'s API. Here are the steps:\\n\\n1. **Set Up**: OpenAI provides an API that can be used for various tasks like text generation, translation, etc. To use the API, you first need to sign up on OpenAI\\'s website and get your API key.\\n\\n2. **Installation**: You should install the OpenAI Python client. You can do this by running the command `pip install openai` in your terminal.\\n\\n3. **Import the Library**: In your Python script, you need to import the OpenAI API by using the command `import openai`.\\n\\n4. **API Key**: Set your API key in your code. You can do this by `openai.api_key = \\'your-api-key\\'`.\\n\\n5. **Use the API**: Now you can use various methods provided by the API for different tasks. For example, you can use the `openai.ChatCompletion.create()` method for a chat-based model, or `openai.Completion.create()` for a completion task.\\n\\nHere\\'s an example of how to use the chat models:\\n\\n```python\\nimport openai\\n\\nopenai.api_key = \\'your-api-key\\'\\n\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\\n    ]\\n)\\n\\nprint(response[\\'choices\\'][0][\\'message\\'][\\'content\\'])\\n```\\n\\nThis script sets up a conversation with the model where the system\\'s role is defined as being a helpful assistant and the user asks a question. The model\\'s response is then printed out.\\n\\nRemember to replace `\\'your-api-key\\'` with your actual API key.\\n\\nPlease refer to the OpenAI API documentation for more detailed information and different use cases: https://beta.openai.com/docs/', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 401, 'total_tokens': 429, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Your API key (replace with your actual key)\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "# Define headers for the request\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "}\n",
    "\n",
    "# Define the data (the conversation you want to have with GPT-4)\n",
    "data = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain how to use OpenAI's API?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response from GPT-4\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Python code demonstrates how to use the OpenAI API to interact with GPT-4 in a conversational manner. \n",
    "\n",
    "Here’s a detailed breakdown of each part of the code and similar examples to help you understand the usage better.\n",
    "\n",
    "# Step-by-Step Explanation\n",
    "\n",
    "    Import Libraries:\n",
    "\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    requests is used to make HTTP requests, which allows us to interact with the OpenAI API.\n",
    "\n",
    "    json is used to encode the data into JSON format for sending and decoding the JSON response from the API.\n",
    "\n",
    "\n",
    "# Set the API Key:\n",
    "\n",
    "    api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "    Replace \"Sample key...\" with your actual API key from OpenAI. The key allows access to the OpenAI API.\n",
    "    Define the API Endpoint:\n",
    "\n",
    "\n",
    "    url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    This URL is the endpoint for the OpenAI GPT-4 chat completion model, which provides conversational responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Headers:\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "    }\n",
    "\n",
    "    The headers include the content type (application/json) and the authorization header, which passes the API key to the OpenAI server for authentication.\n",
    "\n",
    "\n",
    "# Define the Data Payload:\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you explain how to use OpenAI's API?\"}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "\n",
    "# The data dictionary contains:\n",
    "\n",
    "    \"model\": Specifies the model to use, in this case, GPT-4.\n",
    "\n",
    "    \"messages\": An array of conversation messages where:\n",
    "\n",
    "    The first message is from the \"system\" defining the assistant's behavior as \"helpful.\"\n",
    "\n",
    "    The second message is from the \"user,\" which is the question to the assistant.\n",
    "\n",
    "    \"temperature\": Controls the creativity of the response. \n",
    "    Values closer to 0 make the response more deterministic, \n",
    "    while values closer to 1 make it more creative.\n",
    "\n",
    "# Make the Request:\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    Sends a POST request to the OpenAI API with the defined headers and JSON-encoded data payload.\n",
    "\n",
    "    Print the Response:\n",
    "\n",
    "    print(response.json())\n",
    "\n",
    "    The response is decoded from JSON format, and the assistant’s response to the question is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: Ask for a Recipe Suggestion\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a professional chef.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you suggest a quick pasta recipe?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.5\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "print(response.json())\n",
    "\n",
    "System Prompt: Defines the assistant as a “professional chef.”\n",
    "\n",
    "User Message: Asks for a pasta recipe suggestion.\n",
    "\n",
    "Temperature: Set to 0.5 to balance creativity with precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Generate Motivational Quotes\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are an inspiring life coach.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you give me a motivational quote to start my day?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.8\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "System Prompt: Defines the assistant as an “inspiring life coach.”\n",
    "\n",
    "User Message: Requests a motivational quote.\n",
    "\n",
    "Temperature: Set to 0.8 to add a bit more creativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3: Get Coding Advice\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a programming expert.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I optimize a Python script for speed?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.6\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "print(response.json())\n",
    "\n",
    "System Prompt: Defines the assistant as a “programming expert.”\n",
    "\n",
    "User Message: Asks for tips to optimize Python code.\n",
    "\n",
    "Temperature: Set to 0.6 for a slightly creative yet precise response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example tailors the assistant's behavior and responses to the user’s request by adjusting the system prompt and user message. \n",
    "\n",
    "The temperature parameter is set differently depending on how creative or factual you want the response to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "tts_text = \"\"\"\n",
    "Once upon a time, Leo the lion cub woke up to the smell of pancakes and scrambled eggs.\n",
    "His tummy rumbled with excitement as he raced to the kitchen. Mama Lion had made a breakfast feast!\n",
    "Leo gobbled up his pancakes, sipped his orange juice, and munched on some juicy berries.\n",
    "\"\"\"\n",
    "\n",
    "speech_file_path = \"./sounds/default_tts.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1-hd\",\n",
    "    voice=\"alloy\",\n",
    "    input=tts_text,\n",
    ")\n",
    "\n",
    "response.write_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, a golden retriever is considered a good family dog. They are known for their friendly and tolerant attitudes. They are also great with kids and highly adaptable to living with families. Golden Retriever also enjoys participating in family activities and generally easy to train.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR-API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a chat completion request without audio capabilities\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Is a golden retriever a good family dog?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
